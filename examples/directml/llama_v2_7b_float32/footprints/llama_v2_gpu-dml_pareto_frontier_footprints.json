{"0_OrtTransformersOptimization-97923feb029e5bee5bdc57ab766dcab2-5214c6c7dd9651acfbc5ebb1a498712f-gpu-dml": {"parent_model_id": "97923feb029e5bee5bdc57ab766dcab2", "model_id": "0_OrtTransformersOptimization-97923feb029e5bee5bdc57ab766dcab2-5214c6c7dd9651acfbc5ebb1a498712f-gpu-dml", "model_config": {"type": "ONNXModel", "config": {"model_path": {"type": "folder", "config": {"path": "C:\\Users\\pavignol\\projects\\Olive\\examples\\directml\\llama_v2_7b_float32\\cache\\models\\0_OrtTransformersOptimization-97923feb029e5bee5bdc57ab766dcab2-5214c6c7dd9651acfbc5ebb1a498712f-gpu-dml\\output_model"}}, "onnx_file_name": "LlamaV2_7B_float32.onnx", "inference_settings": null, "use_ort_extensions": false, "hf_config": null}}, "from_pass": "OrtTransformersOptimization", "pass_run_config": {"model_type": "gpt2", "num_heads": 32, "hidden_size": 4096, "optimization_options": {"enable_gelu": true, "enable_layer_norm": true, "enable_attention": true, "use_multi_head_attention": true, "enable_skip_layer_norm": false, "enable_embed_layer_norm": true, "enable_bias_skip_layer_norm": false, "enable_bias_gelu": true, "enable_gelu_approximation": false, "enable_qordered_matmul": false, "enable_shape_inference": true, "enable_gemm_fast_gelu": false, "enable_nhwc_conv": false, "enable_group_norm": true, "enable_bias_splitgelu": false, "enable_packed_qkv": true, "enable_packed_kv": true, "enable_bias_add": false}, "opt_level": null, "use_gpu": false, "only_onnxruntime": false, "float16": true, "input_int32": false, "keep_io_types": false, "force_fp32_ops": null, "save_as_external_data": false, "all_tensors_to_one_file": true, "external_data_name": null}, "is_pareto_frontier": true, "metrics": {"value": {"latency-avg": {"value": 62.28094, "priority": 1, "higher_is_better": false}}, "cmp_direction": {"latency-avg": -1}, "is_goals_met": true}, "date_time": 1691902054.479011}}