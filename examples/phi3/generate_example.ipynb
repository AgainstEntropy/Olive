{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add the utils directory to the path\n",
    "sys.path.append(str(Path().resolve().parent / \"utils\"))\n",
    "\n",
    "import numpy as np\n",
    "from generator import ORTGenerator\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "base_model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "ep = \"CUDAExecutionProvider\"\n",
    "ep = \"CPUExecutionProvider\"\n",
    "\n",
    "if ep == \"CUDAExecutionProvider\":\n",
    "    model_path = \"models/phi3-qlora-cuda/qlora-conversion-optimization_fp16-4bit-extract/gpu-cuda_model/model.onnx\"\n",
    "    tiny_codes_path = \"models/phi3-qlora-cuda/qlora-conversion-optimization_fp16-4bit-extract/gpu-cuda_model/adapter_weights.npz\"\n",
    "elif ep == \"CPUExecutionProvider\":\n",
    "    model_path = \"models/phi3-qlora-cpu/qlora-conversion-optimization_fp32-4bit-extract/cpu-cpu_model/model.onnx\"\n",
    "    tiny_codes_path = \"models/phi3-qlora-cpu/qlora-conversion-optimization_fp32-4bit-extract/cpu-cpu_model/adapter_weights.npz\"\n",
    "\n",
    "# load weights\n",
    "tiny_codes_weights = np.load(tiny_codes_path)\n",
    "\n",
    "# create zero weights for the base model\n",
    "base_zero_weights = {key: np.zeros_like(value) for key, value in tiny_codes_weights.items()}\n",
    "\n",
    "# create random weights for control. Show that the fine-tuned adapter is doing something\n",
    "random_weights = {key: np.random.rand(*value.shape).astype(value.dtype) for key, value in tiny_codes_weights.items()}\n",
    "\n",
    "adapters = {\n",
    "    \"base\": {\n",
    "        \"weights\": base_zero_weights\n",
    "    },\n",
    "    \"tiny-codes\": {\n",
    "        \"weights\": tiny_codes_weights,\n",
    "        \"template\": \"### Question: {prompt} \\n### Answer:\"\n",
    "    },\n",
    "    \"random\": {\n",
    "        \"weights\": random_weights\n",
    "    }\n",
    "}\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "\n",
    "# load the generator\n",
    "generator = ORTGenerator(model_path, tokenizer, execution_provider=ep, device_id=6, adapters=adapters, adapter_mode=\"inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Calculate the sum of a list of integers.\"\n",
    "\n",
    "\n",
    "for adapter in adapters:\n",
    "    print(\"Using adapter:\", adapter)\n",
    "    response = generator.generate(prompt, adapter=adapter, max_gen_len=100, use_io_binding=True)\n",
    "    print(response)\n",
    "    print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
