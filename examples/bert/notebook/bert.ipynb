{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic.schema import schema\n",
    "from olive.workflows.run.run import RunConfig\n",
    "run_config_schema = schema([RunConfig])\n",
    "json.dump(run_config_schema, open(\"run_config_schema.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is used to demonstrate how to use the Olive to optimize the BERT model one-by-one with Olive API.\n",
    "## torch model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new olive engine\n",
    "from olive.engine import Engine\n",
    "engine = Engine(execution_providers=[\"CUDAExecutionProvider\"])\n",
    "engine.initialize()\n",
    "\n",
    "# wrapper model with olive\n",
    "from olive.model import PyTorchModel\n",
    "olive_model = PyTorchModel(hf_config={\n",
    "    \"model_name\": \"Intel/bert-base-uncased-mrpc\",\n",
    "    \"task\": \"text-classification\",\n",
    "    \"dataset\": {\n",
    "        \"data_name\":\"glue\",\n",
    "        \"subset\": \"mrpc\",\n",
    "        \"split\": \"validation\",\n",
    "        \"input_cols\": [\"sentence1\", \"sentence2\"],\n",
    "        \"label_cols\": [\"label\"],\n",
    "        \"batch_size\": 1\n",
    "    }\n",
    "})\n",
    "#[!] duplicated data configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olive.data.template import huggingface_data_config_template\n",
    "evaluation_config = {\n",
    "    \"metrics\":[\n",
    "        {\n",
    "            \"name\": \"accuracy\",\n",
    "            \"type\": \"accuracy\",\n",
    "            \"backend\": \"huggingface_metrics\",\n",
    "            \"sub_types\": [\n",
    "                {\"name\": \"accuracy\", \"priority\": 1, \"goal\": {\"type\": \"max-degradation\", \"value\": 0.01}},\n",
    "                {\"name\": \"f1\"}\n",
    "            ],\n",
    "            \"data_config\": huggingface_data_config_template(\n",
    "                model_name=\"bert-base-uncased\",\n",
    "                task=\"text-classification\",\n",
    "                **{\n",
    "                    \"data_name\":\"glue\",\n",
    "                    \"subset\": \"mrpc\",\n",
    "                    \"split\": \"validation\",\n",
    "                    \"input_cols\": [\"sentence1\", \"sentence2\"],\n",
    "                    \"label_cols\": [\"label\"],\n",
    "                    \"batch_size\": 1\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"latency\",\n",
    "            \"type\": \"latency\",\n",
    "            \"sub_types\": [\n",
    "                {\"name\": \"avg\", \"priority\": 2, \"goal\": {\"type\": \"percent-min-improvement\", \"value\": 20}},\n",
    "                {\"name\": \"max\"},\n",
    "                {\"name\": \"min\"}\n",
    "            ],\n",
    "            \"data_config\": huggingface_data_config_template(\n",
    "                model_name=\"bert-base-uncased\",\n",
    "                task=\"text-classification\",\n",
    "                **{\n",
    "                    \"data_name\":\"glue\",\n",
    "                    \"subset\": \"mrpc\",\n",
    "                    \"split\": \"validation\",\n",
    "                    \"input_cols\": [\"sentence1\", \"sentence2\"],\n",
    "                    \"label_cols\": [\"label\"],\n",
    "                    \"batch_size\": 1\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "from olive.hardware.accelerator import DEFAULT_CPU_ACCELERATOR\n",
    "from olive.evaluator.olive_evaluator import OliveEvaluatorConfig\n",
    "evaluation_config = OliveEvaluatorConfig.parse_obj(evaluation_config)\n",
    "torch_result = engine._evaluate_model(\n",
    "    olive_model,\n",
    "    model_id=engine._init_input_model(olive_model),\n",
    "    data_root=None,\n",
    "    evaluator_config=evaluation_config,\n",
    "    accelerator_spec=DEFAULT_CPU_ACCELERATOR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy-accuracy': 0.8602941176470589, 'accuracy-f1': 0.9042016806722689, 'latency-avg': 42.24228, 'latency-max': 43.59108, 'latency-min': 41.78174}\n"
     ]
    }
   ],
   "source": [
    "print(torch_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert torch model to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olive.passes import OnnxConversion\n",
    "from olive.hardware.accelerator import DEFAULT_GPU_CUDA_ACCELERATOR\n",
    "output_model_1 = OnnxConversion(\n",
    "    DEFAULT_GPU_CUDA_ACCELERATOR,\n",
    "    config={\n",
    "        \"target_opset\": 13,\n",
    "        \"user_script\": None,\n",
    "        \"script_dir\": None,\n",
    "    }\n",
    ").run(\n",
    "    olive_model, \n",
    "    data_root=None,\n",
    "    output_model_path=\"./output_models/\",\n",
    "    point=None\n",
    ")\n",
    "#[!] for the pass which requires user_script, we must provide the script_dir and user_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 13:15:19.223388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 13:15:20.211285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1947882/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3304905296.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1947882/3304905296.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'DEFAULT_GPU_CUDA_ACCELERATOR'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1947882/\u001b[0m\u001b[1;33m3304905296.py\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1947882/3304905296.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'DEFAULT_GPU_CUDA_ACCELERATOR'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from olive.passes import OrtTransformersOptimization\n",
    "output_model_2 = OrtTransformersOptimization(\n",
    "    DEFAULT_GPU_CUDA_ACCELERATOR,\n",
    "    config={\n",
    "        \"model_type\": \"bert\",\n",
    "        \"num_heads\": 12,\n",
    "        \"hidden_size\": 768,\n",
    "        \"float16\": True,\n",
    "        \"use_gpu\": True,\n",
    "        \"opt_level\":99,\n",
    "    }\n",
    ").run(output_model_1, None, \"./output_models/trans_opt/\", None)\n",
    "#[!] can not run search along with the passes\n",
    "#[!] cannot leverage the cache mechanism\n",
    "#[!] cannot access the footprint of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packaging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
